{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euler's Method: Obtaining Solutions to ODE's Numerically\n",
    "\n",
    "#### Author: Jaime Sabal\n",
    "#### Date: 03/07/2020\n",
    "\n",
    "In this notebook we explore the extent to which Euler's Method can be used to accurately obtain the solution to an ordinary differential equation. Euler's method follows from the definition of a derivative by the Fundamental Theorem of Calculus:\n",
    "\n",
    "$$\n",
    "\\frac{dx}{dt} = \\lim_{dt\\to0} \\frac{x(t+dt)-x(t)}{dt}\n",
    "$$\n",
    "\n",
    "Moreover, using the approximation that\n",
    "\n",
    "$$ \\frac{dx}{dt} \\approx \\frac{x(t+dt)-x(t)}{dt} $$\n",
    "\n",
    "and subsituting in a simple 1st-order ordinary differential equation (ODE):\n",
    "\n",
    "$$ \\frac{dx}{dt} = -Ax $$\n",
    "\n",
    "we can rearrange to solve for $x(t+dt)$ as a function of $x(t)$:\n",
    "\n",
    "$$ x(t+h) = x(t) -Axh, $$\n",
    "\n",
    "We can thus iteratively solve this ODE, where $h=dt$ is the step taken between each iteration, given some initial condition $x(t_0) = x_0$. More especifically, the update performed on the function upon each increase in the independent variable: $t \\rightarrow t+h$, will have the form\n",
    "\n",
    "$$ x[i+1] = x[i] - A*x[i]*h $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries\n",
    "\n",
    "We start off by importing the necessary libraries: `numpy`, `matplotlib`, `time`, and `math`, which will facilitate the calculations and visualisations done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Necessary Constants that will be Used Throughout Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limits in array of independent variable (t):\n",
    "t_max = 5 #upper t limit \n",
    "t_min = 0 #lower t limit\n",
    "\n",
    "A = 1 #constant in ODE\n",
    "x0 = 1 #initial condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Python function that calculates the solution to any first-order ODE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to perform Euler's Method of solving first-order ODE's numerically\n",
    "def eulers_method(t_min, t_max, h,x0):\n",
    "    \"\"\" Calculates the solution to any first-order ODE for which the derivative of\n",
    "    a function only depends on the function itself. It requires some initial condition \n",
    "    that x(t0)=x0, where t0 is the entry at index 0 of the array of values t. \n",
    "    \n",
    "    Parameters:\n",
    "    · f (function): derivative of function that will be calculated.\n",
    "    · t_min (float/int): smallest value in function domain.\n",
    "    · t_max (float/int): largest value in function domain.\n",
    "    · h (float): step size in iteration.\n",
    "    · x0 (float): initial condition; value of wanted function at time t0 \n",
    "    (index 0 of array t).\n",
    "    \n",
    "    Outputs:\n",
    "    · t_array (1D NumPy array): array of values for the independent variable of the ODE.\n",
    "    · x (1D NumPy array): the computed approximation to the solution of the ODE \n",
    "    from Euler's Method.\n",
    "    · time (float): time taken to compute solution, in seconds.\n",
    "    \"\"\"\n",
    "    \n",
    "    x = [x0] #initialise array of values for our solution\n",
    "    \n",
    "    #setting array of values for independent variable   \n",
    "    t_array = np.arange(t_min,t_max+h,h)\n",
    "    \n",
    "    start = time.time() #start computation timer \n",
    "    \n",
    "    #calculate solution iteratively\n",
    "    for i in range(len(t_array)-1):\n",
    "        x.append(x[i]+ODE(x[i])*h)\n",
    "    \n",
    "    end = time.time() #end computation timer\n",
    "    \n",
    "    #return array of steps used in iteration\n",
    "    # as well as complete array of values for solution \n",
    "    duration = end-start\n",
    "    return t_array,x,duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Python function for the Differential Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ODE(x):\n",
    "    \"\"\"Returns the value of the differential equation dx/dt=-A*x(t) for a given x and t.\n",
    "    \n",
    "    Parameters:\n",
    "    · x (float): Value of independent variable x that our derivative is dependent on.\n",
    "    · t (float): Value of dependent variable t that x is dependent on.\n",
    "    · global variable A (float/int): constant of proportionality between the derivative\n",
    "    of a function and the function itself.\n",
    "    \n",
    "    Output: \n",
    "    · dx (float): Value of derivative dx/dt for the specified x and t\n",
    "    \"\"\"\n",
    "    \n",
    "    deriv_x = -A*x\n",
    "    return deriv_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining a Numerical Solution to ODE:\n",
    "\n",
    "Next, we will use the defined functions `eulers_method` and `ODE` to obtain a numerical solution to the specified ordinary differential equation:\n",
    "\n",
    "$$ \\frac{dx}{dt} = -x $$\n",
    "\n",
    "where, for simplicity, $A=1$. Moroever, we will use the initial condition that $x(t=0)=1$ and a value for the step size of $h=0.99$*. Furthemore, we will use a range of values $0 \\leq t \\leq 5$ to appreciate well the difference between the analytic and numerical solutions later on (since they're asymptotic and both tend to 0 for large values of t)\n",
    "\n",
    "*Note that we must choose a step size small enough that we dont overshoot $x(t)$ to a value outside its known range (this being $x \\epsilon  [0,\\infty]$). For this reason, the step size we choose must be $0 < h < 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = 0.99 #step size\n",
    "\n",
    "#calling our function to solve the differential equation\n",
    "t_num1,x1,duration1 = eulers_method(t_min,t_max,h1,x0)\n",
    "\n",
    "print(\"The array of values for the solution to the differential equation across all t:\\n\"\n",
    "      , x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting and Comparing with Analytical Solution:\n",
    "\n",
    "Since the above ordinary differential equation is separable, we can solve it analytically as such:\n",
    "\n",
    "$$ \\frac{dx}{x} = -t $$\n",
    "\n",
    "$$ln(x) = -t + C$$\n",
    "\n",
    "$$x(t) = e^{-t+C} = e^{C}e^{-t}$$\n",
    "\n",
    "In this case we have defined our initial condition to be $x(t=0)=1$, and hence by plugging this into the equation above we get:\n",
    "\n",
    "$$ x(t=0) = e^{C}e^{0} = 1$$\n",
    "\n",
    "$$ \\therefore e^{C} = 1 $$\n",
    "\n",
    "Resulting in the final analytic solution to the ODE:\n",
    "\n",
    "$$x(t) = e^{-t}$$\n",
    "\n",
    "We can plot this result using the `matplotlib` library and compare it with the acquired numerical solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analytic solution\n",
    "start_anal = time.time() #timer start\n",
    "t_anal = np.linspace(t_min,t_max+h1,500)\n",
    "x_anal = np.exp(-t_anal)\n",
    "end_anal = time.time() #timer end\n",
    "\n",
    "#Time taken to calculate analytic solution\n",
    "duration_anal = end_anal-start_anal\n",
    "\n",
    "#Plotting both solutions in a figure\n",
    "plt.figure()\n",
    "plt.title(\"Comparison of Solutions to ODE with\\n Step Size h=%0.1f for Numerical Solution\"%(h1))\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.grid()\n",
    "plt.plot(t_num1,x1,\"b.\", label=\"Numerical\")\n",
    "plt.plot(t_anal,x_anal,\"r\", label=\"Analytic\")\n",
    "plt.legend(loc=\"best\");\n",
    "\n",
    "print(\"The time taken to calculate each solution:\")\n",
    "print(\"Numerical with h=%0.2f: time=%0.5f\"%(h1,(duration1)), \"seconds\") \n",
    "print(\"Analytic: time=%0.5f seconds\"%(duration_anal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the result shows a solution that has the same trend as the one found analytically, but that approaches its asymptote at $x=0$ at a much quicker rate due to the large step size.\n",
    "\n",
    "We can further extend our analysis by calculating the maximum and percent error when comparing our found numerical solution with the analytic one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Function to Calculate Maximum Error and Percent Error of Numerical Solution\n",
    "\n",
    "Wer define a function below to calculate the root-mean-squared (rms) error between the analytical and numerical solutions as well as the corresponding percent error between them. We calculate the RMS error through the equation [1]:\n",
    "\n",
    "$$RMS Error = \\sqrt{\\frac{\\sum_{i=1}^{n} (\\hat{y_{i}}-y_{i})}{n}}$$\n",
    "\n",
    "where $y_{i}$ is the numerical result and $\\hat{y_{i}}$ is the analytical result for a total of $n$ data points. The RMS percent error is then [2]:\n",
    "\n",
    "$$RMS Percent Error = \\sqrt{\\frac{\\sum_{i=1}^{n}(\\frac{y_{i}}{\\hat{y_{i}}}-1)^{2}}{n}}*100$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_error(x_num,t_num):\n",
    "    \"\"\"Calculates the rms error between two arrays representing the calculated \n",
    "    analytic and numerical solutions to the ordinary differential equation dx/dt=-x.\n",
    "    \n",
    "    Inputs:\n",
    "    · x_num (1D NumPy array): array of values for numerical solution.\n",
    "    · t_num (1D NumPy array): array of values for independent variable of \n",
    "    numerical solution.\n",
    "    \n",
    "    Output:\n",
    "    · max_error (float): maximum error of the numerical solution when comparing it\n",
    "    to the analytic result.\n",
    "    · percent_error (float): percent maximum error between numerical and analytic\n",
    "    solutions.\n",
    "    \"\"\"\n",
    "    adj_x_anal = np.exp(-t_num)\n",
    "    \n",
    "    errors = abs(np.subtract(adj_x_anal,x_num))\n",
    "    \n",
    "    rms_error = np.sqrt(np.mean(errors**2))\n",
    "    \n",
    "    rms_percent_error = np.sqrt(np.mean(((x_num/adj_x_anal)-1)**2))*100\n",
    "    \n",
    "    return rms_error, rms_percent_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum error of Numerical Solution with Step Size $h=0.9$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_error1, percent_error1 = rms_error(x1,t_num1) #calculate value fo rms error and percent error\n",
    "\n",
    "print(\"The rms error between the two functions is:\\n %0.4f\"%(rms_error1))\n",
    "print(\"rms percent error:\\n %0.2f%%\"%(percent_error1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step size $h=0.099$:\n",
    "\n",
    "We can now try to use a smaller step size (by an order of magnitude) of $h=0.09$ to see the effects on the acquired solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = 0.099 #new, smaller, step size\n",
    "\n",
    "#calling our function to solve the differential equation\n",
    "t_num2,x2,duration2 = eulers_method(t_min,t_max,h2,x0)\n",
    "rms_error2,percent_error2 = rms_error(x2,t_num2)\n",
    "\n",
    "#Plotting both solutions in a figure\n",
    "plt.figure()\n",
    "plt.title(\"Numerical solutions to ODE with Different\\n Step Size and its Analytic Solution\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.grid()\n",
    "plt.plot(t_num1,x1,\"b.\", label=\"h=0.99\")\n",
    "plt.plot(t_num2,x2,\"c.\", label=\"h=0.099\")\n",
    "plt.plot(t_anal,x_anal,\"r\", label=\"Analytic\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show();\n",
    "\n",
    "print(\"The time taken to calculate each solution:\")\n",
    "print(\"Numerical with h=%0.2f: %0.5f\"%(h1,(duration1)), \"seconds\") \n",
    "print(\"Numerical with h=%0.3f: %0.5f\"%(h2,(duration2)), \"seconds\") \n",
    "print(\"Analytic: %0.5f seconds\"%(duration_anal))\n",
    "\n",
    "print(\"\\nThe rms error for h=%0.2f is:\\n error = %0.4f \\n Percent error = %0.2f%%\"%(h1,rms_error1,percent_error1))\n",
    "print(\"The rms error for h=%0.3f is:\\n error = %0.4f \\n Percent error = %0.2f%%\"%(h2,rms_error2,percent_error2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "\n",
    "As can be seen, just reducing the step size by an order of magnitude allows us to acquire a much more accurate solution. However, it is worth mentioning that since the algorithmic complexity of `eulers_method` is $O(n)$, by reducing the step size the program will run slower since it has to perform \"$n$\" iterations, where $n=len(t)$ is the discrete number of data points, which increases with smaller step size if the range of values of t is kept the same.\n",
    "\n",
    "Moreover, and as can be seen from the calculations above, the computation time for the numerical solutions using step sizes $h=0.99$ and $h=0.099$ is lower than that of the analytic solution (0.00001s (h=0.99) and 0.00002s (h=0.099) as compared to 0.00024s for the analytic solution**. This is probably due to the fact that the analytic solution has to call the imported library `numpy`). We will discuss this further after performing more trials with smaller step sizes. \n",
    "\n",
    "****Computation times may vary for different trials and/or computer processing powers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions using smaller step sizes:\n",
    "\n",
    "#### $h=0.0099,0.00099,0.000099$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#three different step sizes\n",
    "h3 = 0.0099 \n",
    "h4 = 0.00099\n",
    "h5 = 0.000099\n",
    "\n",
    "#calling our function to solve the differential equation with their corresponding timers\n",
    "t3,x3,duration3 = eulers_method(t_min,t_max,h3,x0)\n",
    "rms_error3,percent_error3 = rms_error(x3,t3)\n",
    "t4,x4,duration4 = eulers_method(t_min,t_max,h4,x0)\n",
    "rms_error4,percent_error4 = rms_error(x4,t4)\n",
    "t5,x5,duration5 = eulers_method(t_min,t_max,h5,x0)\n",
    "rms_error5,percent_error5 = rms_error(x5,t5)\n",
    "\n",
    "#Plotting both solutions in a figure\n",
    "plt.figure()\n",
    "plt.title(\"Numerical solution to ODE with h=%0.4f \\nStep Size and Analytic Solution\"%h3)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.grid()\n",
    "plt.plot(t3,x3,\"r.\", label=\"h=%0.4f\"%h3)\n",
    "plt.plot(t_anal,x_anal,\"c\", label=\"Analytic\", alpha=0.5)\n",
    "plt.legend(loc=\"best\");\n",
    "plt.show()\n",
    "\n",
    "print(\"The rms error for step size h={0:.4f} is:\\n error = {1:e} \\n Percent error = {2:.2f}%\".format(h3,rms_error3,percent_error3))\n",
    "print(\"\\nThe time taken to calculate it was:\\n %0.5f seconds\"%duration3)\n",
    "\n",
    "#Plotting both solutions in a figure\n",
    "plt.figure()\n",
    "plt.title(\"Numerical solution to ODE with h=%0.5f \\nStep Size and Analytic Solution\"%h4)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.grid()\n",
    "plt.plot(t4,x4,\"r.\", label=\"h=%0.5f\"%h4)\n",
    "plt.plot(t_anal,x_anal,\"c\", label=\"Analytic\", alpha=0.5)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show();\n",
    "\n",
    "print(\"The rms error for step size h={0:.5f} is:\\n error = {1:e}\\n Percent error = {2:.3f}%\".format(h4,rms_error4,percent_error4))\n",
    "print(\"\\nThe time taken to calculate it was:\\n %0.6f seconds\"%duration4)\n",
    "\n",
    "#Plotting both solutions in a figure\n",
    "plt.figure()\n",
    "plt.title(\"Numerical solution to ODE with h=%0.6f \\nStep Size and Analytic Solution\"%h5)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.grid()\n",
    "plt.plot(t5,x5,\"r.\", label=\"h=%0.6f\"%h5)\n",
    "plt.plot(t_anal,x_anal,\"c\", label=\"Analytic\", alpha=0.5)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show();\n",
    "\n",
    "print(\"The rms error for step size h={0:.6f} is:\\n error = {1:e}\\n Percent error = {2:.4f}%\".format(h5,rms_error5,percent_error5))\n",
    "print(\"\\nThe time taken to calculate it was:\\n %0.5f seconds\"%duration5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "\n",
    "As can be seen from the values displayed above (below each plot), the maximum error and the percent error between the calculated numerical and analytic solutions are both reduced by approximately the same factor of 10 as the step size $h$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Time Taken to Calculate Numerical Solutions for 5 Different Steps:\n",
    "\n",
    "We will now go on and compare the time taken to calculate each of the numerical solutions with different steps $h$. In the cell below we display each of their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The time taken to calculate each solution:\")\n",
    "print(\"Numerical with h=%0.2f: %0.5f\"%(h1,(duration1)), \"seconds\") \n",
    "print(\"Numerical with h=%0.3f: %0.5f\"%(h2,(duration2)), \"seconds\") \n",
    "print(\"Numerical with h=%0.4f: %0.5f\"%(h3,(duration3)), \"seconds\") \n",
    "print(\"Numerical with h=%0.5f: %0.5f\"%(h4,(duration4)), \"seconds\") \n",
    "print(\"Numerical with h=%0.6f: %0.5f\"%(h5,(duration5)), \"seconds\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the time values increase significantly as we reduce the step taken between iterations. It is also interesting to compare the factors by which the time values change as the step is reduced. Doing this for the first two steps ($h_1$ and $h_2$)**:\n",
    "\n",
    "$$ \\frac{h_2}{h_1} = 0.1 $$\n",
    "\n",
    "$$\\frac{time_2}{time_1} = \\frac{0.00002}{0.00001} = 2 $$\n",
    "\n",
    "Hence, as the step is reduced by a factor of 10, the time required to compute the solution increases by a factor of approximately 1.4. Repeating this for the rest of solutions (where the ratio between step sizes remains constant at 0.1) yields the results:\n",
    "\n",
    "$$\\frac{time_3}{time_2} = \\frac{0.00033}{0.00002} = 16.5  $$\n",
    "\n",
    "\n",
    "$$\\frac{time_4}{time_3} = \\frac{0.00167}{0.00033} = 5.06 $$\n",
    "\n",
    "\n",
    "$$\\frac{time_5}{time_4} = \\frac{0.01554}{0.00167} = 9.31  $$\n",
    "\n",
    "From these results, it can be seen how the computation time increases as the step size decreases by a constant factor of 10.\n",
    "\n",
    "****Note that the values for the times may vary due to differences in the processing power of each computer. However, the above calculations should serve as an approximation of the factor by which these times increase as the step size is reduced.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Computation Time against Step Size\n",
    "\n",
    "We will now attempt to plot the computation time against the step size in order to durther visualize their relationship. However, there is a limit to the extent in which we can do this. As was discovered before, the amount of time taken to compute the numerical solution of this ODE increases at an increasing rate as the step size is reduced by a factor of 10. For this reason, we will only be able to plot a limitted number of data points in a reasonable amount of computation time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 #initialise iterative variable\n",
    "h1 = 0.99 #initialize step size in index 0\n",
    "\n",
    "#initialize arrays for step size and time\n",
    "h_array = [h1]\n",
    "durations = [duration1]\n",
    "\n",
    "#add data to the above arrays using while loop \n",
    "#takes approx. 1min to compute with 8 data points\n",
    "while i<7:   \n",
    "    h1 /= 10\n",
    "    h_array.append(h1)\n",
    "    durations.append(eulers_method(t_min,t_max,h1,x0)[2])\n",
    "    i += 1\n",
    "\n",
    "#make plot\n",
    "plt.figure()\n",
    "plt.plot(h_array,durations,\"r.\")\n",
    "plt.title(\"Computation Time Against Step Size when \\nusing Euler's Method to Solve ODE's\")\n",
    "plt.xlabel(\"Step size\")\n",
    "plt.ylabel(\"Computation Time / s\")\n",
    "plt.grid()\n",
    "\n",
    "#apply logarithmic scale to h and time axes to visualize better\n",
    "plt.xscale(\"log\") \n",
    "plt.yscale(\"log\") \n",
    "plt.savefig(\"Figure_4.png\"); #save figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows how the relationship between computation time and step size is approximately linear in a logarithmic scale. In other words, as the step size is reduced by a factor of 10 each time, the computation time increases by a constant factor that is approximately 10 as well (from the previous result that gave a ratio between computation times of subsequent step sizes of $\\sim (8-11)$ for the smaller step sizes). \n",
    "\n",
    "It is important to note that the h-axis actually shows the factor by which $h$ is smaller than the axis of the independent variable in question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the RMS % Error Between Analytic and Numerical Solutions Against Step Size:\n",
    "\n",
    "We will now plot the RMS % Error between the two solutions for different step sizes as a means to determine a good step size threshold at which the numerical solution is accurate enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make list of rms % errors\n",
    "t_array = [eulers_method(t_min,t_max,step,x0)[0] for step in h_array]\n",
    "x_array = [eulers_method(t_min,t_max,step,x0)[1] for step in h_array]\n",
    "percent_errors = []\n",
    "\n",
    "for t,x in zip(t_array,x_array):\n",
    "    percent_errors.append(rms_error(x,t)[1])\n",
    "                  \n",
    "#make plot\n",
    "plt.figure()\n",
    "plt.plot(h_array,percent_errors,\"r.\")\n",
    "plt.title(\"RMS % Error Against Step Size\")\n",
    "plt.xlabel(\"Step size\")\n",
    "plt.ylabel(\"RMS Percent Error / %\")\n",
    "plt.grid()\n",
    "\n",
    "#apply logarithmic scale to h and time axes to visualize better\n",
    "plt.xscale(\"log\") \n",
    "plt.yscale(\"log\") \n",
    "plt.savefig(\"Figure_5.png\"); #save figure                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the plot, the RMS percent error between the two solutions increases in a linear manner as the step size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we explored the effectiveness and efficiency of using Euler's method to calculate numerical solutions to the differential equation:\n",
    "\n",
    "$$ \\frac{dx}{dt} = -Ax $$\n",
    "\n",
    "for different step sizes $h$. An interesting initial finding was that the maximum error between the calculated numerical and analytic solutions to the ODE was proportional to the step size used. For a step size $h=0.9$, the maximum error was found to be $\\approx 0.3$, and reducing it by a factor of 10 ($h=0.09$) resulted in a maximum error of $\\approx 0.02$. Hence, the latter error is $\\sim 10$ times smaller than the previous result (same order of magnitude as the reduction in step size). Moreover, a quantitative analysis of the time needed to compute these solutions showed that the time needed increases exponentially as the step size is reduced in the same manner, as is shown in the figure below:\n",
    "\n",
    "<img src=\"files/Figure_4 copy.png\" width=\"400\" height=\"200\">\n",
    "\n",
    "Moreover, calculating the dependence of the RMS percent error between the two solutions on the step size we were able to make the following plot:\n",
    "\n",
    "<img src=\"files/Figure_5 copy.png\" width=\"400\" height=\"200\">\n",
    "\n",
    "From this, we see that for a steps size of $\\sim 10^{-3}$ the RMS $\\%$ error is $\\sim 0.1\\%$. Given that for a step size $\\sim 10^{3}$ times smaller than the scale of the axis in question the error between the two solutions is $\\approx0.1\\%$, and the fact that at this step size the numerical solution takes only $0.00033$ seconds to compute, this seems like a good threshold for the step size when using Euler's method to approximate solutions to ODE's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we have explored Euler's method and its effectiveness when approximating numerical solutions to ODE's. However, there are other known methods to do this that have not yet been considered. One of these is the Runge-Kutta method (RK), which derives from Euler's method. As a matter of fact, Euler's method is nothing but the simplest case of the RK methods (first-order). For this reason, this method allows for a faster convergence to a solution. However, this does not necessarily mean that it will result in a smaller error. In general, other methods to obtain numerical solutions to ODE's should be considered depending on the problem in question, but the analysis done in this notebook shows that Euler's method is a good way of obtaining accurate solutions ($<0.5\\%$ error) at a low cost in terms of time efficiency. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "[1]. S. Holmes, “RMS Error,” Statweb, 28-Nov-2000. [Online]. Available: http://statweb.stanford.edu/~susan/courses/s60/split/node60.html#:~:text=and Regression Index-,RMS Error,with a given x value.&text=Squaring the residuals, averaging the,about the predicted y value. [Accessed: 11-Jul-2020].\n",
    "\n",
    "[2]. Fomby, T. (2008). SCORING MEASURES FOR PREDICTION PROBLEMS. http://faculty.smu.edu/tfomby/eco5385_eco6380/lecture/Scoring%20Measures%20for%20Prediction%20Problems.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix:\n",
    "\n",
    "### Comparing the % Change in Computation Time Between Analytic and Numerical Solutions:\n",
    "\n",
    "Having plotted the computation times against their corresponding step size, it is now interesting to see how the percent difference between these and the computation time of the analytic solution changes as the step size is reduced. We compute the percent difference between the two solutions using the equation:\n",
    "\n",
    "$$ \\%\\Delta = \\frac{t_{num}-t_{anal}}{t_{anal}}*100 $$\n",
    "\n",
    "for each step size $h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make array of percent difference between time_anal and the computation\n",
    "#times for each step size\n",
    "time_diff = [100*((dur-duration_anal)/duration_anal) for dur in durations]\n",
    "\n",
    "#plot values in a figure\n",
    "plt.figure()\n",
    "plt.plot(h_array,time_diff, \"b.\")\n",
    "plt.title(\"Percent difference in Computation Time\\n Between Numerical and Analytic solutions for Different Step Sizes\")\n",
    "plt.xlabel(\"Step size / h\")\n",
    "plt.ylabel(\"Percent Difference in Computation Time (%)\")\n",
    "plt.grid()\n",
    "\n",
    "plt.xscale(\"log\") #use log scale for h-axis\n",
    "plt.yscale(\"symlog\") #use symmetrical log scale for percent differences\n",
    "plt.savefig(\"Figure_6.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "From the plot above, we see how for small step sizes ($h=0.99$ and $h=0.099$), the numerical solution is actually calculated faster than the analytic solution. However, as the step size is further reduced by a constant factor of 10, `eulers_method` takes longer to compute and this difference grows exponentially in favour of the latter. Moreover, we had to use a \"symmetrical log\" scale for the percent difference axis due to the fact that for the first two values of $h$ the numerical solution was computed faster than the analytic one and thus resulted in negative values for the percent difference (as they were calculated). Hence, this scale had to be used to allow these negative values to be shown in the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
